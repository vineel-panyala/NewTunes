{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nDN14EXqUT9JU1O3E_a177XD6K2Lw5xX",
      "authorship_tag": "ABX9TyMTLjUPQMDRPQM+vOCEXIwx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vineel-panyala/NewTunes/blob/main/NewTunes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NewTunes\n",
        "\n",
        "\n",
        "\n",
        "[Data Set 1](https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs)\n",
        "\n",
        "[Data Set 2](https://www.kaggle.com/datasets/ambaliyagati/spotify-dataset-for-playing-around-with-sql)"
      ],
      "metadata": {
        "id": "R7RyKTkWxaQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tt84GUemxn0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data Sets"
      ],
      "metadata": {
        "id": "ssCfg5Vlz41G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features_df = pd.read_csv(\"/content/drive/MyDrive/NewTunes Data/spotify_tracks (1).csv\")\n",
        "spotify_tracks_df = pd.read_csv(\"/content/drive/MyDrive/NewTunes Data/tracks_features.csv\")"
      ],
      "metadata": {
        "id": "KzOcfdspyaB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(audio_features_df.columns)\n",
        "print(spotify_tracks_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l45cfI4T0AJJ",
        "outputId": "5275d441-6e20-46b5-dd6d-d26bda116b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'name', 'genre', 'artists', 'album', 'popularity', 'duration_ms',\n",
            "       'explicit'],\n",
            "      dtype='object')\n",
            "Index(['id', 'name', 'album', 'album_id', 'artists', 'artist_ids',\n",
            "       'track_number', 'disc_number', 'explicit', 'danceability', 'energy',\n",
            "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
            "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
            "       'time_signature', 'year', 'release_date'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging DataFrames and Keeping Relevant Columns"
      ],
      "metadata": {
        "id": "-0u5BjzM6N55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.merge(audio_features_df, spotify_tracks_df, on='id')\n",
        "final_df = final_df[['id', 'name_x', 'album_x', 'popularity', 'duration_ms_x', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']]\n",
        "final_df.rename(columns={'name_x': 'name', 'album_x': 'album', 'duration_ms_x':'duration_ms'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "Zz-lrsIC3yhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "Qw6qYyhS7col"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Data to be trained:\n",
        "1. Drop ID, Name, Album Columns\n",
        "2. Drop Rows with Missing Values\n",
        "3. Fill empty values with mean value"
      ],
      "metadata": {
        "id": "5dyJV0Iz840b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = final_df.drop(columns=['id', 'name','album'])\n",
        "cleaned_df = cleaned_df.dropna()\n",
        "cleaned_df = cleaned_df.fillna(cleaned_df.mean())\n",
        "print(cleaned_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZpTeQeA6h8e",
        "outputId": "12b1585b-f9f7-4902-b334-d32707528dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['popularity', 'duration_ms', 'danceability', 'energy', 'key',\n",
            "       'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
            "       'liveness', 'valence', 'tempo', 'time_signature'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure Similar Scaling Measures for each variable"
      ],
      "metadata": {
        "id": "gFv35NZe9VAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "cleaned_df = scaler.fit_transform(cleaned_df)"
      ],
      "metadata": {
        "id": "tflHkwzu87Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch ML"
      ],
      "metadata": {
        "id": "mh2gPSM6-Yea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Data to PyTorch Tensors"
      ],
      "metadata": {
        "id": "I4rz9_OS-Ydy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = cleaned_df[:, 1:]\n",
        "y = cleaned_df[:, 0]\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "y_tensor = y_tensor.view(-1, 1)"
      ],
      "metadata": {
        "id": "NzEnDe9v-xri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "train_size = int(0.75 * len(gen_dataset))\n",
        "test_size = len(gen_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(gen_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
      ],
      "metadata": {
        "id": "gVSZ613S_8pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network Model"
      ],
      "metadata": {
        "id": "qW7xldVtAfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class popularity_predictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(popularity_predictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "\n",
        "model = popularity_predictor(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "MufYNsNZAeVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss() # Gives Mean Squared Error loss for regressions\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Hylvl-d4CpmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSkuwDf_C3L5",
        "outputId": "7aa9fe42-add6-46ee-b328-0af7171e301d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.06751731112599373\n",
            "Epoch 2/100, Loss: 0.05494100116193294\n",
            "Epoch 3/100, Loss: 0.0485832504928112\n",
            "Epoch 4/100, Loss: 0.045079075172543524\n",
            "Epoch 5/100, Loss: 0.04121720604598522\n",
            "Epoch 6/100, Loss: 0.04082063399255276\n",
            "Epoch 7/100, Loss: 0.039750476367771626\n",
            "Epoch 8/100, Loss: 0.03865131679922342\n",
            "Epoch 9/100, Loss: 0.03808351252228022\n",
            "Epoch 10/100, Loss: 0.03780564405024052\n",
            "Epoch 11/100, Loss: 0.03697923719882965\n",
            "Epoch 12/100, Loss: 0.037028530798852446\n",
            "Epoch 13/100, Loss: 0.036993841640651226\n",
            "Epoch 14/100, Loss: 0.0364395834505558\n",
            "Epoch 15/100, Loss: 0.0358468996360898\n",
            "Epoch 16/100, Loss: 0.03526377575471997\n",
            "Epoch 17/100, Loss: 0.03655579388141632\n",
            "Epoch 18/100, Loss: 0.03620578609406948\n",
            "Epoch 19/100, Loss: 0.035971056856215\n",
            "Epoch 20/100, Loss: 0.03546560760587454\n",
            "Epoch 21/100, Loss: 0.0351419672369957\n",
            "Epoch 22/100, Loss: 0.03474135212600231\n",
            "Epoch 23/100, Loss: 0.03493841253221035\n",
            "Epoch 24/100, Loss: 0.034402723610401156\n",
            "Epoch 25/100, Loss: 0.03480595014989376\n",
            "Epoch 26/100, Loss: 0.03488890565931797\n",
            "Epoch 27/100, Loss: 0.03503394834697247\n",
            "Epoch 28/100, Loss: 0.03449141532182694\n",
            "Epoch 29/100, Loss: 0.03468754440546036\n",
            "Epoch 30/100, Loss: 0.034886693209409715\n",
            "Epoch 31/100, Loss: 0.034379270300269126\n",
            "Epoch 32/100, Loss: 0.034002935886383055\n",
            "Epoch 33/100, Loss: 0.034658335708081724\n",
            "Epoch 34/100, Loss: 0.034601302444934846\n",
            "Epoch 35/100, Loss: 0.034544806182384494\n",
            "Epoch 36/100, Loss: 0.03433386124670505\n",
            "Epoch 37/100, Loss: 0.034283388033509256\n",
            "Epoch 38/100, Loss: 0.033350973203778264\n",
            "Epoch 39/100, Loss: 0.035716908238828185\n",
            "Epoch 40/100, Loss: 0.033968986198306086\n",
            "Epoch 41/100, Loss: 0.032979725673794744\n",
            "Epoch 42/100, Loss: 0.03398833405226469\n",
            "Epoch 43/100, Loss: 0.03458127100020647\n",
            "Epoch 44/100, Loss: 0.03360529076308012\n",
            "Epoch 45/100, Loss: 0.034242534264922145\n",
            "Epoch 46/100, Loss: 0.0327075095847249\n",
            "Epoch 47/100, Loss: 0.0338986549526453\n",
            "Epoch 48/100, Loss: 0.03297113962471485\n",
            "Epoch 49/100, Loss: 0.03365038447082043\n",
            "Epoch 50/100, Loss: 0.03216716907918453\n",
            "Epoch 51/100, Loss: 0.03269907291978598\n",
            "Epoch 52/100, Loss: 0.034087194316089156\n",
            "Epoch 53/100, Loss: 0.031751680001616475\n",
            "Epoch 54/100, Loss: 0.03194469306617975\n",
            "Epoch 55/100, Loss: 0.03165933713316917\n",
            "Epoch 56/100, Loss: 0.03177866153419018\n",
            "Epoch 57/100, Loss: 0.031489471718668935\n",
            "Epoch 58/100, Loss: 0.031792919151484966\n",
            "Epoch 59/100, Loss: 0.03144520539790392\n",
            "Epoch 60/100, Loss: 0.032100653275847435\n",
            "Epoch 61/100, Loss: 0.03151913080364466\n",
            "Epoch 62/100, Loss: 0.031282315589487554\n",
            "Epoch 63/100, Loss: 0.031536280922591683\n",
            "Epoch 64/100, Loss: 0.03084395583719015\n",
            "Epoch 65/100, Loss: 0.03182584028691053\n",
            "Epoch 66/100, Loss: 0.031414291635155675\n",
            "Epoch 67/100, Loss: 0.031349551118910315\n",
            "Epoch 68/100, Loss: 0.03064918387681246\n",
            "Epoch 69/100, Loss: 0.03070431686937809\n",
            "Epoch 70/100, Loss: 0.03057057075202465\n",
            "Epoch 71/100, Loss: 0.030663728713989258\n",
            "Epoch 72/100, Loss: 0.03042739722877741\n",
            "Epoch 73/100, Loss: 0.03157633300870657\n",
            "Epoch 74/100, Loss: 0.030482124537229538\n",
            "Epoch 75/100, Loss: 0.029629007540643217\n",
            "Epoch 76/100, Loss: 0.030830562859773637\n",
            "Epoch 77/100, Loss: 0.030552531778812408\n",
            "Epoch 78/100, Loss: 0.029939943924546242\n",
            "Epoch 79/100, Loss: 0.02979308869689703\n",
            "Epoch 80/100, Loss: 0.029011306725442408\n",
            "Epoch 81/100, Loss: 0.029359697923064233\n",
            "Epoch 82/100, Loss: 0.02989698313176632\n",
            "Epoch 83/100, Loss: 0.029593141004443168\n",
            "Epoch 84/100, Loss: 0.028964435309171678\n",
            "Epoch 85/100, Loss: 0.029712937027215957\n",
            "Epoch 86/100, Loss: 0.028637625835835935\n",
            "Epoch 87/100, Loss: 0.029296975955367087\n",
            "Epoch 88/100, Loss: 0.029208360798656942\n",
            "Epoch 89/100, Loss: 0.029325249977409838\n",
            "Epoch 90/100, Loss: 0.029543163254857063\n",
            "Epoch 91/100, Loss: 0.0281546825543046\n",
            "Epoch 92/100, Loss: 0.02823307625949383\n",
            "Epoch 93/100, Loss: 0.02812129259109497\n",
            "Epoch 94/100, Loss: 0.02825933340936899\n",
            "Epoch 95/100, Loss: 0.028263322450220583\n",
            "Epoch 96/100, Loss: 0.02825626228004694\n",
            "Epoch 97/100, Loss: 0.02852358892560005\n",
            "Epoch 98/100, Loss: 0.028460402227938175\n",
            "Epoch 99/100, Loss: 0.028112723864614962\n",
            "Epoch 100/100, Loss: 0.028346027620136736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSTUvV1OuC_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_loss = 0.0\n",
        "    for features, labels in test_loader:\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "print(f\"Test Loss: {total_loss/len(test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNwrIzAzDPvV",
        "outputId": "73a09aa6-29c5-44f6-9067-90be6f60d9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.03319378802552819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  sample_data = X_tensor[:5]\n",
        "  predictions = model(sample_data)\n",
        "  print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTAdM8s7Dam6",
        "outputId": "c32abea4-3eb5-4960-b4b8-f8095ac73f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4549],\n",
            "        [0.6147],\n",
            "        [0.4927],\n",
            "        [0.5277],\n",
            "        [0.5236]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score\n",
        "\n",
        "# Evaluation on test data (loss calculation)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for features, labels in test_loader:\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        all_preds.append(outputs)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    print(f\"Test Loss (MSE): {total_loss/len(test_loader):.4f}\")\n",
        "\n",
        "# Convert lists to tensors for further calculations\n",
        "all_preds = torch.cat(all_preds)\n",
        "all_labels = torch.cat(all_labels)\n",
        "\n",
        "# Define a threshold for binary classification (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred = (all_preds > threshold).float()  # Binary predictions\n",
        "y_true = (all_labels > threshold).float()  # Binary actuals\n",
        "\n",
        "# Calculate accuracy for binary classification\n",
        "accuracy = accuracy_score(y_true.numpy(), y_pred.numpy())\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Calculate additional regression metrics\n",
        "mae = mean_absolute_error(all_labels.numpy(), all_preds.numpy())\n",
        "rmse = np.sqrt(((all_preds - all_labels) ** 2).mean())\n",
        "r2 = r2_score(all_labels.numpy(), all_preds.numpy())\n",
        "\n",
        "# Print out the results\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-Squared: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWMqBBLqpRTW",
        "outputId": "fc084bec-7654-44c4-9e06-dc5d155b9f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss (MSE): 0.0332\n",
            "Test Accuracy: 61.76%\n",
            "Mean Absolute Error (MAE): 0.1565\n",
            "Root Mean Squared Error (RMSE): 0.1922\n",
            "R-Squared: 0.2383\n"
          ]
        }
      ]
    }
  ]
}